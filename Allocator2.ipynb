{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = \"/Users/jiatongchoo/Desktop/Recruit/Tesla/Project/vehicle_allocation.db\"\n",
    "con = sqlite3.connect(db_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "plants = pd.read_csv(\"plants.csv\")\n",
    "colors = pd.read_csv(\"colors.csv\")\n",
    "models = pd.read_csv(\"models.csv\")\n",
    "trims = pd.read_csv(\"trims.csv\")\n",
    "regions = pd.read_csv(\"regions.csv\")\n",
    "regional_demand = pd.read_csv(\"regional_demand.csv\")\n",
    "vehicle_production = pd.read_csv(\"vehicle_production.csv\")\n",
    "transit_time = pd.read_csv(\"transit_time.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_production[\"prod_date\"] = pd.to_datetime(vehicle_production[\"prod_date\"])\n",
    "demand[\"week_start\"] = pd.to_datetime(demand[\"week_start\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aggregate weekly supply\n",
    "vehicle_production[\"week_start\"] = vehicle_production[\"prod_date\"] - pd.to_timedelta(\n",
    "    vehicle_production[\"prod_date\"].dt.dayofweek, unit=\"D\"\n",
    ")\n",
    "base_supply = (\n",
    "    vehicle_production.groupby(\n",
    "        [\"week_start\", \"plant_id\", \"model_code\", \"trim_code\", \"color_code\"], as_index=False\n",
    "    )[\"qty\"].sum()\n",
    "    .rename(columns={\"qty\": \"supply_qty\"})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_demand = demand.rename(columns={\"forecast_qty\":\"demand_qty\"}).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_demand = (\n",
    "    regional_demand.groupby(\n",
    "        [\"week_start\", \"region_id\", \"model_code\", \"trim_code\", \"color_code\"], as_index=False\n",
    "    )[\"forecast_qty\"].sum()\n",
    "    .rename(columns={\"forecast_qty\": \"demand_qty\"})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lead_time_map = transit.set_index([\"plant_id\",\"region_id\"])[\"days_lead_time\"].to_dict()\n",
    "# ship_cost_map = transit.set_index([\"plant_id\",\"region_id\"])[\"per_unit_ship_cost\"].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_matrix = transit_time.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_greedy_allocation(supply_df, demand_df, lead_df, scenario_id):\n",
    "    allocations = []\n",
    "\n",
    "    for week in sorted(demand_df[\"week_start\"].unique()):\n",
    "        week_supply = supply_df[supply_df[\"week_start\"] == week].copy()\n",
    "        week_demand = demand_df[demand_df[\"week_start\"] == week].copy()\n",
    "\n",
    "        for _, d_row in week_demand.iterrows():\n",
    "            remaining = d_row[\"demand_qty\"]\n",
    "\n",
    "            # Plants serving this region\n",
    "            candidates = lead_df.query(\"region_id == @d_row.region_id\")[[\"plant_id\", \"region_id\", \"days_lead_time\"]]\n",
    "\n",
    "            # Merge with available supply for same configuration\n",
    "            merged = (\n",
    "                candidates.merge(\n",
    "                    week_supply,\n",
    "                    how=\"left\",\n",
    "                    on=\"plant_id\"\n",
    "                )\n",
    "                .query(\n",
    "                    \"model_code == @d_row.model_code and trim_code == @d_row.trim_code and color_code == @d_row.color_code\"\n",
    "                )\n",
    "                .dropna(subset=[\"supply_qty\"])\n",
    "                .sort_values(\"days_lead_time\")\n",
    "            )\n",
    "\n",
    "            for _, s_row in merged.iterrows():\n",
    "                if remaining <= 0:\n",
    "                    break\n",
    "                available = s_row[\"supply_qty\"]\n",
    "                allocate = min(available, remaining)\n",
    "                if allocate > 0:\n",
    "                    allocations.append(\n",
    "                        {\n",
    "                            \"scenario_id\": scenario_id,\n",
    "                            \"week_start\": week,\n",
    "                            \"plant_id\": s_row[\"plant_id\"],\n",
    "                            \"region_id\": d_row[\"region_id\"],\n",
    "                            \"model_code\": d_row[\"model_code\"],\n",
    "                            \"trim_code\": d_row[\"trim_code\"],\n",
    "                            \"color_code\": d_row[\"color_code\"],\n",
    "                            \"allocated_qty\": int(allocate),\n",
    "                            \"implied_lead_days\": int(s_row[\"days_lead_time\"]),\n",
    "                        }\n",
    "                    )\n",
    "                    # reduce available supply and demand\n",
    "                    week_supply.loc[\n",
    "                        (week_supply[\"plant_id\"] == s_row[\"plant_id\"])\n",
    "                        & (week_supply[\"model_code\"] == s_row[\"model_code\"])\n",
    "                        & (week_supply[\"trim_code\"] == s_row[\"trim_code\"])\n",
    "                        & (week_supply[\"color_code\"] == s_row[\"color_code\"]),\n",
    "                        \"supply_qty\",\n",
    "                    ] -= allocate\n",
    "                    remaining -= allocate\n",
    "    return pd.DataFrame(allocations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Baseline\n",
    "alloc_baseline = run_greedy_allocation(base_supply, base_demand, lead_matrix, scenario_id=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jb/_hhv0vg53q5_6m25qfc8klvr0000gn/T/ipykernel_65909/614626507.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 57.6  15.2  34.4  61.6 159.2  35.2  88.8 128.8  36.   11.2  20.   47.2\n",
      " 110.4  28.   62.4 106.4  71.2  28.8  41.6  62.4 160.8  47.2 101.6 164.\n",
      "  54.4  12.8  20.   44.8 100.8  35.2  45.6 121.6  62.4  24.   43.2  68.\n",
      " 178.4  48.8  89.6 176.   53.6  12.8  21.6  38.4  84.8  28.8  64.   88.\n",
      "  68.8  20.   32.   71.2 157.6  52.8  86.4 165.6  44.   15.2  22.4  40.8\n",
      "  96.   28.8  56.8 115.2  57.6  16.8  29.6  61.6 116.   31.2  84.8 148.8\n",
      "  47.2   8.   20.8  54.4 103.2  27.2  49.6  93.6  64.8  16.8  44.   73.6\n",
      " 145.6  40.   82.4 139.2  32.8  10.4  19.2  40.  102.4  36.8  60.8 113.6\n",
      "  61.6  16.   25.6  68.  144.8  34.4  92.  135.2  35.2   4.8  22.4  45.6\n",
      "  97.6  21.6  60.  103.2  56.   29.6  42.4  76.  149.6  48.8  78.4 146.4\n",
      "  36.8  11.2  25.6  35.2 111.2  30.4  57.6  99.2  50.4  16.   27.2  54.4\n",
      " 127.2  36.   72.8 121.6  39.2  14.4  19.2  40.   94.4  24.8  57.6  94.4\n",
      "  63.2  17.6  35.2  60.8 147.2  36.8  82.4 158.4  36.   11.2  18.4  43.2\n",
      " 100.8  21.6  61.6  88.   56.8  16.8  41.6  60.  129.6  34.4  85.6 126.4\n",
      "  29.6   6.4  19.2  39.2  74.4  24.8  51.2 100.8  82.4  14.4  45.6  70.4\n",
      " 156.8  36.8  79.2 135.2  47.2   8.   36.8  35.2  78.4  28.   60.   90.4\n",
      "  62.4  14.4  31.2  50.4 136.   42.4  91.2 169.6  44.8  11.2  26.4  39.2\n",
      " 114.4  28.   60.8 116.   22.4   4.    8.   21.6  52.8  17.6  23.2  40.8\n",
      "   7.2   2.4   5.6   9.6  32.   12.   20.   32. ]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  reduced_supply.loc[reduced_supply[\"plant_id\"] == \"FRE\", \"supply_qty\"] *= 0.8\n"
     ]
    }
   ],
   "source": [
    "#Fremont Incident\n",
    "reduced_supply = base_supply.copy()\n",
    "reduced_supply.loc[reduced_supply[\"plant_id\"] == \"FRE\", \"supply_qty\"] *= 0.8\n",
    "alloc_fremont_cut = run_greedy_allocation(reduced_supply, base_demand, lead_matrix, scenario_id=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Allocation completed: 1957 total records written\n"
     ]
    }
   ],
   "source": [
    "alloc_all = pd.concat([alloc_baseline, alloc_fremont_cut], ignore_index=True)\n",
    "alloc_all.to_sql(\"allocation_result\", con, if_exists=\"replace\", index=False)\n",
    "print(f\"✅ Allocation completed: {len(alloc_all)} total records written\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Regional Allocation Comparison (% Change):\n",
      "            Baseline  Fremont −20%   Change %\n",
      "region_id                                   \n",
      "CC            32703         32057  -1.975354\n",
      "EC            20036         18747  -6.433420\n",
      "WC             4322          3874 -10.365571\n"
     ]
    }
   ],
   "source": [
    "summary = (\n",
    "    alloc_all.groupby([\"scenario_id\", \"region_id\"])[\"allocated_qty\"]\n",
    "    .sum()\n",
    "    .reset_index()\n",
    "    .pivot(index=\"region_id\", columns=\"scenario_id\", values=\"allocated_qty\")\n",
    ")\n",
    "summary.columns = [\"Baseline\", \"Fremont −20%\"]\n",
    "summary[\"Change %\"] = (summary[\"Fremont −20%\"] - summary[\"Baseline\"]) / summary[\"Baseline\"] * 100\n",
    "print(\"\\nRegional Allocation Comparison (% Change):\\n\", summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "alloc_all.to_csv(\"Allocation_result2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_nearest_first_allocator(supply_df, demand_df, lead_map, cost_map):\n",
    "#     \"\"\"\n",
    "#     Greedy nearest-first allocator.\n",
    "#     - Supply indexed by (week, plant, model, trim, color)\n",
    "#     - Demand by (week, region, model, trim, color)\n",
    "#     - For each demand tuple, rank plants by (lead_time, ship_cost) and allocate greedily.\n",
    "#     Returns: (allocations_df, backlog_df)\n",
    "#     \"\"\"\n",
    "#     # Index supply by (week, SKU) -> { plant_id: remaining_qty }\n",
    "#     sup_idx = defaultdict(dict)\n",
    "#     for row in supply_df.itertuples(index=False):\n",
    "#         key = (row.week_start, row.model_code, row.trim_code, row.color_code)\n",
    "#         sup_idx[key][row.plant_id] = sup_idx[key].get(row.plant_id, 0) + int(row.supply_qty)\n",
    "\n",
    "#     # Collapse/Sort demand\n",
    "#     dcols = [\"week_start\",\"region_id\",\"model_code\",\"trim_code\",\"color_code\",\"demand_qty\"]\n",
    "#     dem = (demand_df[dcols]\n",
    "#            .groupby(dcols[:-1], as_index=False)[\"demand_qty\"].sum()\n",
    "#            .sort_values([\"week_start\",\"region_id\",\"model_code\",\"trim_code\",\"color_code\"]))\n",
    "#     def ordered_plants(region_id: str, candidate_plants: list[str]):\n",
    "#         ranked = []\n",
    "#         for p in candidate_plants:\n",
    "#             lt = lead_map.get((p, region_id))\n",
    "#             if lt is None:\n",
    "#                 continue  # skip lanes that don't exist\n",
    "#             cost = cost_map.get((p, region_id), np.inf)\n",
    "#             ranked.append((lt, cost, p))\n",
    "#         ranked.sort(key=lambda x: (x[0], x[1], x[2]))  # lead time, then cost, then plant_id\n",
    "#         return ranked\n",
    "\n",
    "#     allocations = []\n",
    "#     backlog_rows = []\n",
    "\n",
    "#     for row in dem.itertuples(index=False):\n",
    "#         week, region, m, t, c, need = row\n",
    "#         need = int(need)\n",
    "#         sku_key = (week, m, t, c)\n",
    "\n",
    "#         if sku_key not in sup_idx:\n",
    "#             if need > 0:\n",
    "#                 backlog_rows.append((week, region, m, t, c, need))\n",
    "#             continue\n",
    "\n",
    "#         plant_remaining = sup_idx[sku_key]\n",
    "#         ranking = ordered_plants(region, list(plant_remaining.keys()))\n",
    "\n",
    "#         for lt, cost, plant in ranking:\n",
    "#             if need <= 0:\n",
    "#                 break\n",
    "#             rem = int(plant_remaining.get(plant, 0))\n",
    "#             if rem <= 0:\n",
    "#                 continue\n",
    "#             take = min(rem, need)\n",
    "#             plant_remaining[plant] = rem - take\n",
    "#             need -= take\n",
    "#             allocations.append({\n",
    "#                 \"week_start\": week,\n",
    "#                 \"plant_id\": plant,\n",
    "#                 \"region_id\": region,\n",
    "#                 \"model_id\": m,\n",
    "#                 \"trim_id\": t,\n",
    "#                 \"color_id\": c,\n",
    "#                 \"allocated_qty\": int(take),\n",
    "#                 \"implied_lead_days\": int(lt),\n",
    "#                 \"implied_ship_cost\": float(cost),\n",
    "#             })\n",
    "\n",
    "#         if need > 0:\n",
    "#             backlog_rows.append((week, region, m, t, c, int(need)))\n",
    "\n",
    "#     alloc_df = pd.DataFrame(allocations)\n",
    "#     backlog_df = pd.DataFrame(backlog_rows, columns=[\n",
    "#         \"week_start\",\"region_id\",\"model_id\",\"trim_id\",\"color_id\",\"backlog_qty\"\n",
    "#     ])\n",
    "#     return alloc_df, backlog_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_fremont_cut(supply_df: pd.DataFrame, fraction_of_normal: float = 0.2) -> pd.DataFrame:\n",
    "    \"\"\"Reduce Fremont capacity to a given fraction (0.2 = 20% of normal).\"\"\"\n",
    "    sup2 = supply_df.copy()\n",
    "    mask = sup2[\"plant_id\"].astype(str).eq(\"FRE\")\n",
    "    sup2.loc[mask, \"supply_qty\"] = (sup2.loc[mask, \"supply_qty\"] * fraction_of_normal).round().astype(int)\n",
    "    return sup2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline\n",
    "alloc_base, backlog_base = run_nearest_first_allocator(\n",
    "    weekly_supply, weekly_demand, lead_time_map, ship_cost_map\n",
    ")\n",
    "alloc_base[\"scenario_id\"] = 1\n",
    "backlog_base[\"scenario_id\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fremont at 20%\n",
    "weekly_supply_shock = apply_fremont_cut(weekly_supply, 0.2)\n",
    "alloc_shock, backlog_shock = run_nearest_first_allocator(\n",
    "    weekly_supply_shock, weekly_demand, lead_time_map, ship_cost_map\n",
    ")\n",
    "alloc_shock[\"scenario_id\"] = 2\n",
    "backlog_shock[\"scenario_id\"] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine\n",
    "alloc_all = pd.concat([alloc_base, alloc_shock], ignore_index=True)\n",
    "backlog_all = pd.concat([backlog_base, backlog_shock], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_alloc = (\n",
    "    alloc_all.groupby([\"scenario_id\",\"region_id\"], as_index=False)[\"allocated_qty\"]\n",
    "             .sum()\n",
    "             .rename(columns={\"allocated_qty\":\"total_allocated\"})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_lead = (\n",
    "    alloc_all.assign(w=alloc_all[\"allocated_qty\"])\n",
    "             .groupby([\"scenario_id\",\"region_id\"], as_index=False)\n",
    "             .apply(lambda g: pd.Series({\n",
    "                 \"avg_lead_days\": (g[\"implied_lead_days\"]*g[\"w\"]).sum() / max(g[\"w\"].sum(), 1)\n",
    "             }))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "alloc_all.to_csv(\"Allocation_result2.csv\", index=False)\n",
    "# backlog_all.to_csv(BACKLOG_CSV, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
